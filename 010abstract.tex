Dialog systems or chatbots are computer programs that can interact with humans either using a speech interface or text interface. 
% Building dialog systems are gaining popularity due to two major reasons. One to accomplish a task, such as purchasing a mobile phone from Amazon, internet users prefer a simple chat interface compared to navigating through websites or a mobile app. Two, mobile phone users spend most of their time using email or messaging applications.
Based on the application, dialogs systems can be divided into two categories: open domain and task oriented. Dialog systems that converse with an intention to accomplish a task such as recommending a restaurant or booking a flight tickets are task oriented dialog systems. Such systems gennerally need to consult a Knowledge Base (KB) with stored information to accomplish the task. End-to-end neural networks trained for these task-oriented dialogs are expected to be immune to any changes in this KB which can evolve with time. However, existing approaches breakdown when asked to handle such changes. The failure is mostly due to the inability to handle Out-of-Vocabulary (OOV) words and the inability to perform simple reasoning over the knowledge base results such as suggest without repetition and sorting based on a field.
% and a simple analysis shows that there exists a huge gap when evaluated using task specific metrics.
% Research in open domain dialog systems have progressed to a state where given a large corpus of conversation logs, the deep learning models can learn to converse end-to-end without the need of defining hand crafted, domain specific rules. Most of the research on modeling dialog systems has been focused on only learning to converse by remembering how conversation are sustained in the training examples. There has been very little work around on how to learn an end-to-end task oriented dialog system that requires access to a knowledge base to accomplish a given task. 

% The existing end-to-end task oriented dialog system which uses knowledge base perform well only on open domain dialog system evaluation metrics, a simple analysis shows that there exists a huge gap when evaluated using task specific metrics. The failure is mostly due to the inability to handle OOV words, inability to perform simple reasoning over knowledge base results such as suggest without repetition and sorting based on a field over.



% We first solve the limitations in the existing model by proposing a deep network that can consume knowledge base results and perform basic reasoning. To accomplish this we propose a hierarchical attention network with the ability to perform location based addressing. The overall goal of this research is to learn a usable task oriented dialog system from long human-human chat transcripts. To achieve the goal, we propose to solve the following problems: one, dialog system that can perform complex reasoning such as inferring from more than one knowledge base result to generate a response. The existing systems access the knowledge base just once during the conversation, we propose to extend this by modeling a system that is capable to conversing by accessing the knowledge base more than once. For example, when purchasing a product such as mobile phone, the user describes her requirements,  based on the mobile phones available in the knowledge base, the system should help narrow down the option based on the results. We then wish to work on knowledge bases that contains semi-structured fields along with the structured fields. Finally, we wish to learn a usable dialog system using human to human conversations.

% \noindent The Knowledge Base (KB) used for real-world applications, such as booking a movie or restaurant reservation, keeps changing over time. End-to-end neural networks trained for these task-oriented dialogs are expected to be immune to any changes in the KB. However, existing approaches breakdown when asked to handle such changes. 
We studied the correlation between the learned language model and the knowledge base incorporation and conjectured that we must strive to create a system that learns both mutually exculsive of the other, i.e. in a disentangled manner.
We propose an encoder-decoder architecture (\sys) with a novel Bag-of-Sequences (\textsc{BoSs}) memory, which facilitates such disentangled learning. Consequently, the KB can be modified with new knowledge without a drop in interpretability. We find that \sys\ outperforms state-of-the-art models, with considerable improvements (\textgreater10\%) on bAbI OOV test sets and other humsan-human datasets. We also systematically create adversarial attacks that introduce modifications to the KB in an attempt to measure the extent of disentanglement and show that \sys\ remains robust to all such attacks.
% We also systematically modify existing datasets to measure disentanglement and show \sys\ to be robust to KB modifications.

Generally the training set dialogs in task-oriented systems use an explicit API for KB retreival which must be manually annotated within the dialogs themselves. We attempt to go one step further by reducing the amount of annotations needed to train such task-oriented dialogs by predicting the correct API without it being explicitly mentioned. We generate this API using an RL-based decoder. The results from this API are then used to generate responses by our response decoder which serve as feedback (reward) to train the RL decoder. We created a novel architecture that would be capable to mitigte two critical problems: data bias (multiple APIs fetch similar KB results) and length bias (preference of the RL decoder to predict short length APIs over longer ones, despite worse results). Our system was successfully able to achieve similar performance on the unannotated dataset as compared to the fully API annotated dataset.
% which trains based on the feedback (reward) it receives on its ability to generate correct responses on the results extracted by the predicted API call.
