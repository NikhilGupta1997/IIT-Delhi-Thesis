Task-oriented dialog agents converse with a user with the goal of accomplishing a specific task and often interact with a knowledge-base (KB). For example, a restaurant reservation agent \cite{hen2014word} will be grounded  to a KB that contains the names of restaurants, and their details.  

In real-world applications, the KB information could change over time. For example, (1) a KB associated with a movie ticket booking system gets updated every week based on new film releases, and (2) a restaurant reservation agent, trained with the knowledge of eateries in one city, may be deployed in other cities with an entirely different range of establishments. In such situations, the system should have the ability to conform to new-found knowledge unseen during its training. Ideally, the training algorithm must learn to disentangle the language model from the knowledge interface model. This separation will enable the system to generalize to KB modifications, without a loss in performance.  

Moreover, for achieving good progress towards the user's task, the agent must also retain the ability to  draw inferences based on past utterances and the KB. Notably, we find that existing approaches either achieve this disentanglement or effective progress towards the task, but not both.  

For instance, Mem2Seq \cite{mem2seq} exhibits satisfactory performance when tested on the training KB. It represents the dialog history and the KB knowledge as a \emph{bag of words} in a flat memory arrangement. This enables Mem2Seq to revisit each word several times, as needed, obtaining good performance. But at the same time, flat memory prevents it from capturing any surrounding context -- this deteriorates its performance rapidly when the amount of new unseen information in the KB increases, as shown in Figure \ref{fig:camrest}. On the other hand, the performance of copy augmented sequence-to-sequence network (Seq2Seq+Copy) \cite{eric2017copy}, is robust to changes in the KB, but fails to achieve acceptable task-oriented performance. It captures context by representing the entire dialog history as one continuous \emph{sequence}.
However, it can be difficult for a sequence encoder to reason over long dialogs found in real-world datasets and its ability to learn the task gets hampered.  

We propose \sys, a novel network that effectively disentangles the language and knowledge models, and also achieves state-of-the-art performance on three existing datasets.  

To achieve this, \sys\ makes two design choices. First, it encodes the conversational input as a {\em bag of sequences} (\textsc{BoSs}) memory, in which the input representation is built at two levels of abstraction. The \emph{higher level} flat memory encodes the KB tuples and utterances to facilitate effective inferencing over them. The \emph{lower level} encoding of each individual utterance and tuple is constructed via a sequence encoder (Bi-GRU). This enables the model to maintain the sequential context surrounding each token, aiding in better interpretation of unseen tokens at test time. Second, we augment the standard cross-entropy loss used in dialog systems with an additional loss term to encourage the model to only copy KB tokens in a response, instead of generating them via the language model. This combination of sequence encoding and additional loss (along with dropout) helps in effective disentangling between language and knowledge.  

We perform evaluations over three datasets -- bAbI \cite{BordesW16}, CamRest \cite{wenEMNLP2016}, and Stanford Multi-Domain Dataset \cite{Ericsigdial}. Of these, the last two are real-world datasets. We find that \sys\ is competitive or significantly better on standard metrics in all datasets as compared to state-of-the-art baselines. We also introduce a {\em knowledge adaptability} (KA) evaluation, in which we systematically increase the percentage of previously unseen entities in the KB. We find that \sys\ is highly robust across all percentage levels. Finally, we also report a human-based evaluation and find that \sys\ responses are frequently rated higher than other baselines.  

Overall, our contributions are:

\begin{enumerate}
    \item We propose \sys, a novel architecture to disentangle the language model from knowledge incorporation in task-oriented dialogs.
    \item We introduce a {\em knowledge adaptability} evaluation to measure the ability of dialog systems to scale performance to unseen KB entities.
    \item Our experiments show that \sys\ is competitive or significantly better, measured via standard metrics, than the existing baselines on three datasets.
\end{enumerate}

We release our code and {\em knowledge adaptability} (KA) test sets for further use by the research community. \url{ https://github.com/dair-iitd/BossNet}. 

\section{Introduction}
\label{sec:intro}
Dialog systems, also referred to as chatbots or virtual agents are systems that can converse with a human to help with their informational needs. Dialog systems are used in a wide range of applications such as personal assistants in mobile phones, technical support services, chit chat, product enquiries, IVR systems and entertainment. Some of the popular dialog systems includes Apple's Siri, Google Now, Microsoft's Cortana, Amozon's Alexa and Google's Smart Reply. Most of the dialog systems that are being used for real word applications are hand crafted by a dialog designers and also very specific to a domain. Even though using such hand crafted rules provides the flexibility to build a interpretable dialog system, it require a great amount of effort from the dialog designer to create one from scratch for a new domain. It also applies to scenarios where the existing chatbot's capability has to be extended or improved.

Recent advancements in the field of neural networks has shown us that data-driven approaches outperform systems with custom hand crafted features. This has been proven for a number of NLP tasks such as part of speech tagging, named entity recognition, speech recognition, etc. This trend is now being observed in the area of building dialog systems. Research on data driven approaches for modeling dialogs have started to shadow the research around improving the traditional hand crafted dialog systems. The data driven approaches have the ability to learn to mimic a human with just access to a large corpus of conversation logs. The system learnt using data driven approaches can at best be used to provide suggestions to possible next responses or provide context based auto complete features in social media, email client or chat applications. For example, the \textit{smart reply} option in GMail. This option scans the email conversation so far and suggests three possible responses to reply with. These systems are far from performing a full fledged conversation and help accomplish user's goal.

We now introduce the standard architecture of dialog systems and describe each of its components. Breaking down the dialog system into smaller components not only helps us in understanding how dialog systems work, but also helps in defining the scope of our research. Most of the dialog systems consists three main components: 1) natural language understanding (NLU) unit, 2) dialog manager and 3) natural language generator (NLG). The architecture is shown in Figure \ref{fig:arch}. This architecture assumes the mode of interaction is text. If the mode of interaction is speech rather than text, then that would require two additional modules to bridge the two modalities. They are the speech recognizer and the speech synthesizer. The speech recognizer converts speech to text, while the speech synthesizer converts text to speech.

The NLU maps a natural language user input onto a structured understanding space. The structured understanding space would either be hand-crafted by the dialog designer or a vector of real numbers. More details on the various types of structured understanding space is described in section~\ref{sec:relatedwork}. The dialog manager (DM) is the core-component of the dialog system. Both the input and the output of the dialog manager are structured. The main job is to maintain a state of the conversation so far and suggest how the system should respond to it. The DM learns to update the state of the conversation using the NLU's output after every exchange and signals the NLG on how to respond. Finally, the NLG helps convert the dialog manager's signals to a natural language text that is consumable by the user. Every dialog system does not need to specifically have all the three components, some tend to combine adjacent modules and design (or learn) them together. For example, in some systems the DM and NLG can be combined and designed/learned together.

\subsection{Problem Definition}

We now define the scope of the problem we wish explore, by answering the following questions: 1) \textit{what is end-to-end learning ?}, 2) \textit{What is are task oriented dialog systems?} and 3)\textit{why is knowledge base necessary ?}

\textbf{End-to-End Learning}:  While building a dialog system, the components could either be built using hand crafted rules or can also be statistical machine learning model that learns from a provided set of examples (data-driven). A complete dialog system can thus have some components that are built using rules and some that are learnt using data driven approaches. As mentioned previously, not all dialog system built needs to have all three components, in some cases, the designer can decide to combine both dialog manager and the NLG into a single modules. This way the component can be learnt by using a set of (NLU output, expected natural language response) pairs. Even though this bypasses the need for explicitly annotating the dialog manager output for each dialog exchange, the complexity of the module increases thereby demanding a lot more data to train. The approach where all the three components are combined together and examples of (user input in natural language, expected response in natural language) pairs are used to learn a dialog model, is referred to as \textit{end to end} dialog models. Note that in end to end learning, the intermediate output space may be  defined, but examples are not annotated with expected intermediate outputs.

\textbf{Task Oriented}: Application of dialog systems can be broadly categorized into two types: open domain (non-task oriented) dialog systems and task oriented dialog systems. The main difference between the two approaches is that, the objective of the former is usually broad and not well defined (abstract), where as the objective of the latter is  narrow and well-defined. For example, the restaurant reservation domain dialogs falls under task oriented systems. The goal could be, given a set of options (price range: moderate, location: east Delhi), the system should be able to suggest the right restaurant that is acceptable by the user. A large portion of the research in data driven approaches for dialog modeling has been around non-task oriented. Some examples include chit-chat and language learning. Applications such as restaurant reservation, flight booking, travel enquiry and bus enquiry belong to the task-oriented setting.  One advantage of working on task oriented dialogs over the non-task oriented is easy of defining an evaluation techniques to measure the performance of the system. The performance of the system can be measure by the percentage of conversations where the dialog system was able to help the user achieve her goal. 

Question answering systems and task oriented dialog systems are very similar to each other. The major difference between the two is that, in question answering all details necessary to achieve the task are provided in a single shot, where as in task oriented dialog, the user does not necessarily provide all the information required to achieve the task and its the job of the dialog system to collect them. The dialog systems also provides the ability to carry over context when switching between tasks.

\textbf{Knowledge Base in the Loop}: These are the subset of dialog system that requires access to a knowledge base to respond to user input. Some examples are  using a database of bus running status by a bus enquiry system, using a knowledge base of restaurants by a restaurant reservation systems and using a open domain knowledge base such as Freebase for a dialog system that answers general knowledge questions. There has been a large amount of work on using databases in systems that use hand crafted features for modeling dialog. The community has recently (in 2017) started to explore the area of learning data-driven dialog models grounded by a knowledge base.

To summarize, the goal of our research is to build a dialog system that takes as input 1) a large set of task oriented conversation logs between a user and an agent/domain expert, 2) a knowledge base used to generate agent response and learn a dialog system that can mimic the agent to accomplish a user's task.  

\subsection{Motivation}
\label{subsec:motivation}
In this section, we motivate our problem by clearly define the gap between what the state-of-the-art, data driven approaches for dialog learning is capable of and what it takes to build a usable end-to-end task oriented dialog system that requires knowledge base in the loop.\\

\noindent
\textbf{Why cant already proven non-task oriented models be used}

While end to end non-task oriented (open domain) dialog systems are being used in real world applications \cite{smartreply}, designers still prefer using hand crafted rules for modeling task oriented dialogs. The main reason for success in non-task oriented setting is that, models have largely been evaluated (and applied) in scenarios where, given the conversation so far the system is expected to predict just the immediate next response. Such modeling requires the system to learn a language model and a mapping from the context to the response. But in case of task oriented settings, the requirements/expectations are much more. It is not just required to generate the next utterance based on the context, but understand the global picture of what the task is, what all details are necessary to finish the task, what is the optimal way or strategy to request for missing details and then decide what the next utterance should be. Also, in chit chat bot (non-task oriented) making a mistake in a single turn is not very costly, where as in flight booking system (task-oriented) making a single mistake (mis-interpreting a source city) could turn out to be very costly. Even though a large section of real world applications such flight booking, tourist enquiry system, technical service support, basic medical consultations fall under this category, there has been very little focus so far.

In addition to task oriented setting, when a knowledge base is added into the loop, the system should now also be able to learn when to query a knowledge base, how to incorporate the results from the knowledge base into the conversation. This makes the problem much harder. Hence models that have been proven to work on non-task oriented systems cannot be used for task-oriented applications.\\

\noindent
\textbf{Limitations of state-of-the-art task oriented approaches}

There has been very little progress made end-to-end task oriented dialogs, as most of the proposed approaches has been around using hand crafted rules to either build the entire system, or to define the structured space of each sub-components output. The only work published so far on end to end task oriented conversation has the following limitations:
\begin{enumerate}
\item Both the human and the agent utterances in the dataset are fabricated using rules. This simulated dataset is very simple compared to human to human conversation logs.
\item The system performance is has acceptable accuracy on  non-task oriented evaluation metrics, but the performance is very poor on task oriented evaluation metrics
\item The system is unable to learn simple patterns (that are exhibited in the train corpora) required to perform a task oriented dialog. Some simple patterns are listed below:
\begin{itemize}
\item construct responses based on results from the database. In fact some responses have results that are not in the set of results retrieved from the database
\item not repeating already suggested options
\item retrieve simple relations from set of database results (such as phone number of a restaurant, address of a restaurant)
\end{itemize}  
\item the approach assumes the database does not change over time and all possible field values are known in advance, it has no support for field values that have never been encountered so far (OOVs)
\item The system proposed has a very limited view of the knowledge base. It assumes that it can only perform simple {\emph SELECT} operation with {\emph WHERE} clauses over the knowledge base
\end{enumerate} 

\subsection{Overview of the Research Plan}
\label{subsec:proposed-intro}
The overall goal of this research is to build a {\emph usable} task oriented dialog system that can learn to converse by using long human-human chat transcripts. The dialog system should also be able refers to use a knowledge base to understand the user’s needs and respond back. The term {\emph usable} is emphasized as we wish the system to have the task level performance, defined based on the task, to be high.

Identifying the right dataset to work with is one of the major challenges in NLP, as it helps in identifying the right direction of research. We have identified a human to human dialog dataset to help us guide through this journey. The dataset has been provided to us by \textit{1mg}, an e-commerce health care company based in Gurgaon. The conversation logs are human (patient) to human (doctor) with the goal of suggesting them either with the right test or suggesting the right specialist to contact. But before the goal can be reached, the doctor should also collect the necessary information to be in a position to suggest any of them. We have also been provided with a list of databases related to medicines, drugs-medicines, etc.

With the ultimate goal of solving the problem mentioned above, we plan to solve a sequence of sub-problems that builds up and finally results in a system that can perform end to end learning using human to human conversation with a knowledge base in the loop. The sequence of sub-problems are listed below

\begin{enumerate}
	\item \textbf{Basic Knowledge Base Reasoning Using Memory Networks}: Model a deep learning based solution that can effectively use results from a knowledge base query to generate response
	\item \textbf{Complex Knowledge Base Reasoning Using Memory Networks}: Extend the deep neural architecture to generate responses based on a collection of  knowledge base result. In other words, the system should have the ability to aggregate the results to accomplish a task. 
	\item \textbf{Learning End to End task oriented dialog with Multiple Knowledge Bases}: The deep neural architecture should be able to utilize from than one knowledge base for conversation modeling. In addition to that, the model should not only work on structured fields (mostly single entity) but also on semi-structured fields (free text)
	\item \textbf{Learning End to End Task Oriented Dialogs from Human to Human Conversations}: Identify the challenges in building an end to end task oriented model using human to human conversation by using the data provided by 1mg
\end{enumerate}

In the next section we provide a comprehensive summary of all the works that have been done in the area of dialog modeling and other relevant areas such as question answering, memory in neural networks, etc. In the final section, the three broad level plans listed in section \ref{subsec:proposed-intro} are described in detail.

